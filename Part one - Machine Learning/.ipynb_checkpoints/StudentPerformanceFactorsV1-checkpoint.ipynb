{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mount Google Drive (if running in Colab)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Load the dataset, handling missing values and inconsistencies\n",
    "file_path = '/content/corrupted_datasetStudentPerformanceFactors.csv'\n",
    "missing_values = [\"--\", \"N/A\", \"NULL\", \"Not Available\", \"Unknown\", \"\"]\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, na_values=missing_values)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please check the path.\")\n",
    "    exit()  # Exit the script if the file isn't found"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Initial Inspection",
   "id": "91f45c16ea8bc27b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Original Data - Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nOriginal Data - Info:\")\n",
    "df.info()\n",
    "print(\"\\nOriginal Data - Describe:\")\n",
    "print(df.describe(include='all'))\n",
    "print(\"\\nOriginal Data - Shape:\")\n",
    "print(df.shape)"
   ],
   "id": "400ac091dc4ffd75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Data Cleaning",
   "id": "b17be65d6fe370e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Handle Missing Values and Inconsistencies",
   "id": "3a252dc83da8650a"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'Hours_Studied' to numeric, coercing errors to NaN\n",
    "df['Hours_Studied'] = pd.to_numeric(df['Hours_Studied'], errors='coerce')\n",
    "\n",
    "# Convert 'Attendance' to numeric, coercing errors to NaN\n",
    "df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce')\n",
    "\n",
    "# Convert 'Previous_Scores' to numeric, coercing errors to NaN\n",
    "df['Previous_Scores'] = pd.to_numeric(df['Previous_Scores'], errors='coerce')"
   ],
   "id": "6e070af69c1ee793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert 'Family_Income' to numeric, coercing errors to NaN, and handling potential errors\n",
    "try:\n",
    "    df['Family_Income'] = pd.to_numeric(df['Family_Income'], errors='raise') #errors raise to make sure all errors are handled, see below\n",
    "except ValueError as e:\n",
    "    print(f\"\\nError converting 'Family_Income' to numeric: {e}\")\n",
    "    print(\"Unique non-numeric values in 'Family_Income':\", df['Family_Income'].loc[pd.to_numeric(df['Family_Income'], errors='coerce').isna()].unique())"
   ],
   "id": "9eb97846ebeb0fe7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert 'Family_Income' to numeric\n",
    "df['Family_Income'] = df['Family_Income'].replace({'Low':1, 'Medium':2, 'High':3})\n",
    "\n",
    "# Clean up 'Exam_Score'\n",
    "df['Exam_Score'] = pd.to_numeric(df['Exam_Score'], errors='coerce')\n",
    "\n",
    "# Deal with other missing values\n",
    "df['Gender'] = df['Gender'].replace({'Male': 'MALE', 'Female': 'FEMALE'})"
   ],
   "id": "5bbab99228f01095"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.describe()\n",
    "\n",
    "# Impute numerical missing values with the median\n",
    "for col in [\n",
    "    'Hours_Studied', 'Attendance', 'Previous_Scores',\n",
    "    'Exam_Score', 'Sleep_Hours', 'Physical_Activity'\n",
    "]:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "df.describe()"
   ],
   "id": "91d03d1ee0706c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.info()\n",
    "\n",
    "for col in [\n",
    "    'Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
    "    'Internet_Access', 'Tutoring_Sessions', 'School_Type','Peer_Influence',\n",
    "    'Learning_Disabilities', 'Parental_Education_Level', 'Distance_from_Home',\n",
    "    'Gender','Family_Income', 'Teacher_Quality', 'Motivation_Level'\n",
    "]:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "df.info()"
   ],
   "id": "9883d7a5def44e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Print data types of each column\n",
    "print(df.dtypes)"
   ],
   "id": "30342134148676b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check the data types and unique values again\n",
    "print(\"\\nCleaned Data - Info:\")\n",
    "df.info()\n",
    "print(\"\\nCleaned Data - Head:\")\n",
    "print(df.head())"
   ],
   "id": "e97012c914076f31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.describe(include='all')\n",
    "print(df.shape)"
   ],
   "id": "1449c38b6f669c11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3: Feature Engineering\n",
    "df['Parental_Involvement_Score'] = df['Parental_Involvement'].map({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "df['Parental_Education_Score'] = df['Parental_Education_Level'].map({'High School': 1, 'College': 2, 'Postgraduate': 3})\n",
    "df['Combined_Parental_Score'] = df['Parental_Involvement_Score'] + df['Parental_Education_Score']"
   ],
   "id": "a195c79d35416601"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Exploratory Data Analysis (EDA)",
   "id": "1609995f775078bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Univariate Analysis",
   "id": "204d4fbecfc9a9e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Histograms for numerical features\n",
    "numerical_cols = ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Family_Income', 'Exam_Score','Combined_Parental_Score']\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col], kde=False) # Removed kde, can also do it with\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ],
   "id": "fd4a7edbfc513098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Bar plots for categorical features\n",
    "categorical_cols = ['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities',\n",
    "                    'Internet_Access', 'Tutoring_Sessions', 'Teacher_Quality', 'School_Type',\n",
    "                    'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level', 'Gender']\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "id": "c66d521ff628a8e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Scatter plots against 'Exam_Score'\n",
    "for col in numerical_cols:\n",
    "    if col != 'Exam_Score':  # Avoid Exam_Score vs. Exam_Score\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.scatterplot(x=col, y='Exam_Score', data=df)\n",
    "        plt.title(f'{col} vs. Exam_Score')\n",
    "        plt.show()"
   ],
   "id": "389eb13505f0b42a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Box plots for categorical features against 'Exam_Score'\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=col, y='Exam_Score', data=df)\n",
    "    plt.title(f'{col} vs. Exam_Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "id": "8467890be2070a6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Correlation matrix (for numerical features)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "id": "ca17baef4a6feaae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.to_csv('/content/drive/MyDrive/Colab Notebooks/datasets/cleaned_student_performance.csv', index=False)",
   "id": "cfec224cc426dabb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Code Explanation:\n",
    "\n",
    "Import Libraries: Imports necessary libraries (pandas, numpy, matplotlib, seaborn).\n",
    "\n",
    "Load Dataset:\n",
    "\n",
    "Loads the corrupted_datasetStudentPerformanceFactors.csv file into a pandas DataFrame.\n",
    "\n",
    "Uses na_values to specify a list of strings that should be treated as missing values (NaN). This is crucial for handling the various inconsistent missing value representations.\n",
    "\n",
    "Prints the head(), info(), and describe() of the original DataFrame to show the initial state of the data. This helps you understand the columns, data types, and initial summary statistics (including missing value counts).\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "pd.to_numeric(errors='coerce'): This is the key to handling the mixed data types and non-numeric entries in numerical columns.\n",
    "\n",
    "errors='coerce' is essential. It tells pandas to convert anything that cannot be converted to a number into NaN. This is how we get rid of the text/symbols in the numerical columns.\n",
    "\n",
    "After using pd.to_numeric(errors='coerce'), you'll have NaN values wherever there were strings or symbols.\n",
    "\n",
    "Imputation (Missing Value Handling): After converting columns to numeric and handling inconsistent strings, you'll likely have more NaN values. The code shows how to:\n",
    "\n",
    "Impute numerical columns with the median (more robust to outliers than the mean). df[col].fillna(df[col].median(), inplace=True) fills missing values in the column col with the median of that column.\n",
    "\n",
    "Impute categorical columns with the mode (most frequent value). df[col].fillna(df[col].mode()[0], inplace=True) fills missing values in the column col with the most frequent value in that column. mode() returns a Series, so [0] is used to get the first (and usually only) mode.\n",
    "\n",
    "Handling the inconsistent values in 'Gender': Used map function to make the strings consistent.\n",
    "\n",
    "Feature Engineering:\n",
    "\n",
    "Created a new column as combined_parental_involvement_education by combining Parental_Involvement and Parental_Education_Level.\n",
    "\n",
    "Verification: df.info() and df.head() are used again to show the cleaned data. This is important for demonstrating the effect of your cleaning steps.\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "\n",
    "Univariate Analysis: Creates histograms and count plots (bar plots for categorical variables) to visualize the distribution of each variable individually. This helps you understand:\n",
    "\n",
    "Numerical: Shape (skewness, modality), central tendency (where is the \"middle\"), spread (how wide is the distribution), outliers.\n",
    "\n",
    "Categorical: Frequency of each category, class imbalance.\n",
    "\n",
    "Bivariate Analysis:\n",
    "\n",
    "Scatter Plots: Show the relationship between each numerical feature and the 'Exam_Score'. Look for trends (positive, negative, non-linear).\n",
    "\n",
    "Box Plots: Show the distribution of 'Exam_Score' for each category of a categorical variable. Look for differences in the median, spread, and presence of outliers across categories.\n",
    "\n",
    "Correlation Matrix: Calculates and displays the correlation coefficients between all pairs of numerical features. This helps identify strong linear relationships (+1 = perfect positive, -1 = perfect negative, 0 = no linear relationship).\n",
    "\n",
    "Save Cleaned Data (Optional): Saves the cleaned DataFrame to a new CSV file. This is useful for subsequent steps (like model building) without having to rerun the cleaning process every time."
   ],
   "id": "6e6f86bb1836f08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
