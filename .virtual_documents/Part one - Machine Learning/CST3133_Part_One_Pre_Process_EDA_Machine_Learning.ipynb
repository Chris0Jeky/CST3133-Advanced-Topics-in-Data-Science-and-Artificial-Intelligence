############################################
# 1. IMPORT LIBRARIES & MOUNT (if needed)
############################################

import pandas as pd
import numpy as np
import random
import seaborn as sns
import matplotlib.pyplot as plt

sns.set_style("whitegrid")
plt.rcParams["figure.dpi"] = 100





############################################
# 2. LOAD DATASET
############################################

missing_values = [
    "Not Available", "N/A", "na", "NaN", "nan",
    "NULL", "Unknown", "--", "not available",
    "unknown", "null", ""
]

df = pd.read_csv("content/Final_corrupted_dataset.csv", na_values=missing_values)

print("Initial dataset shape:", df.shape)
# df.head(10)






############################################
# 3. REMOVE DUPLICATES
############################################

df.drop_duplicates(inplace=True)
df.reset_index(drop=True, inplace=True)
print("After removing duplicates, shape =", df.shape)






############################################
# 4. QUICK INSPECTION
############################################

print("\n--- INFO ---")
df.info()

print("\n--- DESCRIBE (include='all') ---")
display(df.describe(include='all'))

print("\n--- SAMPLE ROWS ---")
display(df.sample(5))






############################################
# 5. CONVERT WRITTEN-OUT NUMBERS TO DIGITS
############################################

word_to_number_dict = {
    "zero": 0, "one": 1, "two": 2, "three": 3, "four": 4,
    "five": 5, "six": 6, "seven": 7, "eight": 8, "nine": 9,
    "ten": 10, "eleven": 11, "twelve": 12, "thirteen": 13,
    "fourteen": 14, "fifteen": 15, "sixteen": 16,
    "seventeen": 17, "eighteen": 18, "nineteen": 19
}
tens_dict = {
    "twenty": 20, "thirty": 30, "forty": 40, "fifty": 50,
    "sixty": 60, "seventy": 70, "eighty": 80, "ninety": 90
}

def words_to_numbers(value):
    """Convert English words (like 'sixty-five') to an integer if possible."""
    if not isinstance(value, str):
        return value  # If it's already numeric or NaN, return as-is

    word = value.strip().lower()
    # Direct 0-19
    if word in word_to_number_dict:
        return word_to_number_dict[word]
    # Direct tens (20,30,...90)
    if word in tens_dict:
        return tens_dict[word]
    # Compound numbers "twenty-three", "ninety-nine", etc.
    if "-" in word:
        parts = word.split("-")
        if len(parts) == 2:
            part1, part2 = parts
            if part1 in tens_dict and part2 in word_to_number_dict:
                return tens_dict[part1] + word_to_number_dict[part2]
    # Not recognized => return original
    return value

# Define numeric columns that might have textual numbers
possible_text_nums = [
    "Hours_Studied", "Sleep_Hours", "Previous_Scores",
    "Tutoring_Sessions", "Physical_Activity", "Exam_Score"
]

# Converting
for col in possible_text_nums:
    if col in df.columns:
        df[col] = df[col].apply(words_to_numbers)






############################################
# 6. FORCE NUMERIC COLUMNS
############################################

# We expect these columns to be numeric
numeric_cols = [
    "Hours_Studied", "Attendance", "Sleep_Hours",
    "Previous_Scores", "Tutoring_Sessions",
    "Physical_Activity", "Exam_Score"  # If it exists
]

for col in numeric_cols:
    if col in df.columns:
        # Convert to numeric, coerce to NaN if unconvertible
        df[col] = pd.to_numeric(df[col], errors='coerce')






############################################
# 7. FIX INCONSISTENT STRINGS (e.g. 'low' -> 'Low')
############################################

df.replace({"low": "Low", "high": "High", "medium": "Medium"}, inplace=True)

# Also unify 'Male'/'Female' if needed
# More robust approach below with mapping






############################################
# 8. HANDLE MISSING VALUES
############################################

# (A) Numeric columns => fill with median
for col in numeric_cols:
    if col in df.columns:
        median_val = df[col].median()
        df[col] = df[col].fillna(median_val)

# (B) Categorical columns => fill with mode
# Define some likely categorical columns
cat_cols = [
    "Parental_Involvement", "Access_to_Resources", "Extracurricular_Activities",
    "Motivation_Level", "Internet_Access", "Family_Income", "Teacher_Quality", "School_Type", "Peer_Influence", "Learning_Disabilities", "Parental_Education_Level", "Distance_from_Home",
    "Gender"
]


# Define categorical replacements
categorical_replacements = {
    "Parental_Involvement": ["Low", "Medium", "High"],
    "Access_to_Resources": ["Low", "Medium", "High"],
    "Extracurricular_Activities": ["Yes", "No"],
    "Motivation_Level": ["Low", "Medium", "High"],
    "Internet_Access": ["Yes"],
    "Family_Income": ["Low", "Medium"],
    "Teacher_Quality": ["Low", "Medium", "High"],
    "School_Type": ["Public"],
    "Peer_Influence": ["Positive", "Neutral", "Negative"],
    "Learning_Disabilities": ["No"],
    "Parental_Education_Level": ["High School", "College", "Post Graduate"],
    "Distance_from_Home": ["Near", "Moderate"],
    "Gender": ["Male", "Female"]
}

# Fill missing categorical values randomly
for col, choices in categorical_replacements.items():
    if col in df.columns:
        df[col].fillna(random.choice(choices), inplace=True)





############################################
# 9. NORMALIZE CATEGORICAL STRINGS
############################################

def normalize_strings(series, valid_values):
    """ Convert series to lowercase, strip spaces, map to valid_values if found. """
    series = series.astype(str).str.strip().str.lower()
    mapping = {v.lower(): v for v in valid_values}
    return series.map(mapping).fillna(series)  # if not found, keep original

# For "Low"/"Medium"/"High" columns:
lmh_cols = ["Parental_Involvement", "Access_to_Resources", "Motivation_Level", "Teacher_Quality", "Family_Income"]
for col in lmh_cols:
    if col in df.columns:
        df[col] = normalize_strings(df[col], ["Low", "Medium", "High"])

# For yes/no columns:
yn_cols = ["Internet_Access", "Extracurricular_Activities", "Learning_Disabilities"]
for col in yn_cols:
    if col in df.columns:
        df[col] = normalize_strings(df[col], ["Yes", "No"])

# For "School_Type" => "Public"/"Private"
if "School_Type" in df.columns:
    df["School_Type"] = normalize_strings(df["School_Type"], ["Public", "Private"])

# For "Peer_Influence" => "Positive"/"Neutral"/"Negative"
if "Peer_Influence" in df.columns:
    df["Peer_Influence"] = normalize_strings(df["Peer_Influence"], ["Positive", "Neutral", "Negative"])

# For "Distance_from_Home" => "Near"/"Moderate"/"Far"
if "Distance_from_Home" in df.columns:
    df["Distance_from_Home"] = normalize_strings(df["Distance_from_Home"], ["Near", "Moderate", "Far"])

# For "Parental_Education_Level" => "High School", "College", "Postgraduate"
if "Parental_Education_Level" in df.columns:
    df["Parental_Education_Level"] = normalize_strings(df["Parental_Education_Level"],["High School", "College", "Post Graduate", "Postgraduate"])

# For "Gender" => "Male"/"Female"
if "Gender" in df.columns:
    df["Gender"] = normalize_strings(df["Gender"], ["Male", "Female"])

#Print all values in unique values in each column
for col in df.columns:
    print(f"\nColumn: {col}")
    print(df[col].unique())





############################################
# 10. MAP CATEGORIES TO NUMERIC
############################################

# Apply one-hot encoding
df = pd.get_dummies(df, columns=categorical_replacements.keys(), dtype=int)






############################################
# 11. OPTIONAL: CLIP & SCALE NUMERIC
############################################

# Outlier clipping & standardizing 'Hours_Studied'
if "Hours_Studied" in df.columns:
    lb = np.percentile(df["Hours_Studied"], 1)
    ub = np.percentile(df["Hours_Studied"], 99)
    df["Hours_Studied"] = df["Hours_Studied"].clip(lb, ub)

    mean_val = df["Hours_Studied"].mean()
    std_val = df["Hours_Studied"].std()
    df["Hours_Studied"] = (df["Hours_Studied"] - mean_val) / std_val

# Could scale 'Sleep_Hours', 'Physical_Activity', etc.






############################################
# 12. FINAL CHECK
############################################

print("\n--- FINAL df.info() ---")
df.info()

print("\n--- HEAD ---")
display(df.head(10))

# Confirm no missing values
print("\n--- MISSING VALUES ---")
print(df.isnull().sum())

# Print all values in unique values in each column
for col in df.columns:
    print(f"\nColumn: {col}")
    print(df[col].unique())






############################################
# 13. EXPLORATORY DATA ANALYSIS
############################################

# (A) Histograms for numeric columns
num_cols_for_plot = df.select_dtypes(include=[np.number]).columns.tolist()

for col in num_cols_for_plot:
    plt.figure(figsize=(5,3))
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f"Distribution of {col}")
    plt.tight_layout()
    plt.show()

# (B) Countplots for any columns still object dtype
cat_cols_for_plot = df.select_dtypes(include=[object]).columns.tolist()

for col in cat_cols_for_plot:
    plt.figure(figsize=(5,3))
    sns.countplot(x=df[col])
    plt.title(f"Distribution of {col}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# (C) Scatter: each numeric vs. 'Exam_Score' (if it exists)
if "Exam_Score" in df.columns:
    for col in num_cols_for_plot:
        if col != "Exam_Score":
            plt.figure(figsize=(5,3))
            sns.scatterplot(x=df[col], y=df["Exam_Score"])
            plt.title(f"{col} vs. Exam_Score")
            plt.tight_layout()
            plt.show()

# (D) Correlation Heatmap
num_data = df.select_dtypes(include=[np.number])
if num_data.shape[1] > 1:
    plt.figure(figsize=(8,6))
    corr = num_data.corr()
    sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap")
    plt.show()






############################################
# 14. SAVE CLEANED DATASET
############################################

df.to_csv("content/Final_cleaned_dataset.csv", index=False)
print("Cleaned dataset saved to 'cleaned_student_performance.csv'")






#####################################
# ADVANCED EDA SECTION
#####################################

import seaborn as sns
import matplotlib.pyplot as plt

# 1) UNIVARIATE ANALYSIS

# 1A) Histograms & KDE for numeric columns
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

print("=== Histograms & KDE for Numeric Columns ===")
for col in numeric_cols:
    plt.figure(figsize=(5,3))
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f"Distribution of {col}")
    plt.tight_layout()
    plt.show()

# 1B) Boxplots for numeric columns (quick outlier check)
# for col in numeric_cols:
#     plt.figure(figsize=(4,3))
#     sns.boxplot(x=df[col])
#     plt.title(f"Boxplot: {col}")
#     plt.tight_layout()
#     plt.show()

# 1C) Countplots for any remaining categorical columns
cat_cols = df.select_dtypes(include=[object]).columns.tolist()
print("=== Countplots for Categorical Columns ===")
for col in cat_cols:
    plt.figure(figsize=(5,3))
    sns.countplot(x=col, data=df)
    plt.title(f"Countplot: {col}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# 2) BIVARIATE ANALYSIS

# 2A) Pairwise Scatter among numeric columns
print("=== Pairwise Scatter (Pairplot) ===")
if len(numeric_cols) <= 10:
    sns.pairplot(df[numeric_cols], corner=True, diag_kind='kde')
    plt.suptitle("Pairplot of Numeric Features", y=1.02)
    plt.show()

# 2B) If 'Exam_Score' is numeric, let's see correlation with each numeric col
if "Exam_Score" in df.columns:
    for col in numeric_cols:
        if col != "Exam_Score":
            plt.figure(figsize=(5,3))
            sns.scatterplot(x=df[col], y=df["Exam_Score"])
            plt.title(f"{col} vs. Exam_Score")
            plt.tight_layout()
            plt.show()

# 2C) Boxplots or Violin plots for each categorical vs. 'Exam_Score'
if "Exam_Score" in df.columns and cat_cols:
    for col in cat_cols:
        plt.figure(figsize=(5,3))
        sns.boxplot(x=col, y="Exam_Score", data=df)
        plt.title(f"{col} vs. Exam_Score")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# 3) MULTIVARIATE - CORRELATION HEATMAP
num_data = df.select_dtypes(include=[np.number])
if num_data.shape[1] > 1:
    plt.figure(figsize=(8,6))
    corr_matrix = num_data.corr()
    sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap (Numeric Features)")
    plt.tight_layout()
    plt.show()






























############################################
# MACHINE LEARNING - PART 1: REGRESSION MODEL
############################################

# Import the necessary libraries for machine learning
from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets
from sklearn.ensemble import RandomForestRegressor    # Our main regression algorithm
from sklearn.metrics import mean_squared_error, r2_score  # For model evaluation
import numpy as np  # For numerical operations

# Step 1: Define target and feature variables
# --------------------------------------------
# We're using Exam_Score as our target variable (what we want to predict)
# All other numeric columns will be used as features (predictors)
y = df['Exam_Score']  # Target: The student's exam score
x = df.drop(['Exam_Score'], axis=1)  # Features: All other columns

# Step 2: Split the data into training and testing sets
# ----------------------------------------------------
# We use 80% of our data for training the model and reserve 20% for testing
# Setting random_state ensures reproducibility of results
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Step 3: Train the Random Forest Regression model
# -----------------------------------------------
# Random Forest is an ensemble learning method that builds multiple decision trees and
# combines their predictions for better accuracy and to prevent overfitting
best_rf = RandomForestRegressor(
    n_estimators=100,     # Number of trees in the forest
    max_depth=None,       # Maximum depth of the trees (None means unlimited)
    min_samples_split=2,  # Minimum samples required to split an internal node
    min_samples_leaf=1,   # Minimum samples required to be at a leaf node
    random_state=42       # Ensures reproducibility
)

# Fit the model to our training data
best_rf.fit(X_train, y_train)

# Step 4: Evaluate the model's performance
# ----------------------------------------
# Make predictions on our test set
y_pred = best_rf.predict(X_test)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # Root Mean Squared Error
r2 = r2_score(y_test, y_pred)  # R-squared, proportion of variance explained

print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

# Step 5: Analyze feature importance
# ----------------------------------
# Random Forests provide a measure of how important each feature is for prediction
# We extract this information to identify which factors most strongly influence exam scores
feature_importance = best_rf.feature_importances_

# Sort features by importance (descending order)
sorted_idx = np.argsort(feature_importance)[::-1]
sorted_features = [x.columns[i] for i in sorted_idx]
sorted_importance = feature_importance[sorted_idx]

# Visualize feature importance with a bar chart
plt.figure(figsize=(10, 8))
plt.barh(range(len(sorted_importance)), sorted_importance)
plt.yticks(range(len(sorted_importance)), sorted_features)
plt.xlabel('Importance')
plt.title("Random Forest Feature Importance")
plt.tight_layout()
plt.show()

# Convert to DataFrame for better readability
importance_df = pd.DataFrame({
    'Feature': sorted_features,
    'Importance': sorted_importance
})
print(importance_df)

# Step 6: Feature Selection - Remove Less Important Features
# ---------------------------------------------------------
# Based on feature importance, we can simplify our model by keeping only
# the most influential features, which often leads to similar performance
# with a more interpretable model

# Set a threshold to remove features with very low importance (e.g., less than 0.01)
threshold = 0.01
important_features = [feature for feature, importance in
                     zip(sorted_features, sorted_importance) if importance >= threshold]
print(f"Selected {len(important_features)} important features")

# Reduce dataset to only important features
X_reduced = x[important_features]
X_train_reduced, X_test_reduced = train_test_split(X_reduced, test_size=0.2, random_state=42)

# Step 7: Retrain Model with Reduced Features
# -------------------------------------------
# Train a new Random Forest using only the important features
best_rf_reduced = RandomForestRegressor(
    n_estimators=100,
    max_depth=None,
    min_samples_split=2,
    min_samples_leaf=1,
    random_state=42
)
best_rf_reduced.fit(X_train_reduced, y_train)

# Step 8: Evaluate the simplified model
# -------------------------------------
# Test if feature selection maintained or improved performance
y_pred_reduced = best_rf_reduced.predict(X_test_reduced)
mse_reduced = mean_squared_error(y_test, y_pred_reduced)
rmse_reduced = np.sqrt(mse_reduced)
r2_reduced = r2_score(y_test, y_pred_reduced)

print(f"Reduced Model - Mean Squared Error: {mse_reduced:.2f}")
print(f"Reduced Model - Root Mean Squared Error: {rmse_reduced:.2f}")
print(f"Reduced Model - R² Score: {r2_reduced:.2f}")

# Compare the full and reduced models
print("\nComparison:")
print(f"Full model features: {x.shape[1]}, Reduced model features: {len(important_features)}")
print(f"Performance difference (R²): {r2 - r2_reduced:.4f}")


############################################
# MACHINE LEARNING - PART 2: CLASSIFICATION MODEL
############################################

# In this section, we'll convert the exam score prediction problem into a classification task
# where we predict grade categories (A, B, C, D, F) rather than exact scores

# Step 1: Discretize the continuous Exam_Score into grade categories
# -----------------------------------------------------------------
# Converting numerical scores into letter grade ranges allows us to treat this
# as a classification problem instead of regression

# Categorize the Exam_Score column into grade ranges
# Define bins (merging 50-54 into 55-59 and keeping 95-101 as the last range)
bins = [50, 59] + list(range(60, 95, 5)) + [101]  # Corrected last bin to match the range

# Define labels ensuring one less than bins
labels = ['F'] + [f"{chr(64 + (i//2))}{'-' if i % 2 else '+'}" for i in range(8, 0, -1)]

# Apply binning - this creates a new column with categorical grade ranges
df['Grade_Category'] = pd.cut(df['Exam_Score'], bins=bins, labels=labels, include_lowest=True)

# Convert range labels to float by taking the midpoint - useful for certain visualizations
df['Grade_Numeric'] = df['Grade_Category'].cat.codes

# Display how many values are in each range to check class balance
grade_counts = df['Grade_Category'].value_counts().sort_index()
print(grade_counts)

# Visualize the distribution of grades
plt.figure(figsize=(10, 6))
sns.countplot(x='Grade_Category', data=df, order=grade_counts.index)
plt.title('Distribution of Grades')
plt.xlabel('Grade Category')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()



# Step 2: Prepare data for classification
# --------------------------------------
# Import necessary libraries for classification tasks
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

# Convert target to categorical
y = df['Grade_Category']  # Target is now the grade category
X = df.drop(['Exam_Score', 'Grade_Category', 'Grade_Numeric'], axis=1)  # Features

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Train Random Forest Classifier
# -------------------------------------
# Random Forest works well for classification tasks and can handle categorical targets
rf = RandomForestClassifier(n_estimators=200, class_weight="balanced", random_state=42)
rf.fit(X_train, y_train)

# Step 4: Make predictions and evaluate the classifier
# --------------------------------------------------
# Generate predictions on the test set
y_pred_rf = rf.predict(X_test)

# Calculate basic accuracy
accuracy = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy: {accuracy:.4f}")

# Step 5: Detailed performance evaluation
# --------------------------------------
# Evaluate with more detailed metrics beyond simple accuracy

# Classification Report provides precision, recall, and F1-score for each class
print("\nClassification Report (Random Forest):\n", classification_report(y_test, y_pred_rf))

# Generate Confusion Matrix to see which classes are confused with each other
conf_matrix = confusion_matrix(y_test, y_pred_rf)

# Create a heatmap for better visualization of the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=grade_counts.index,
            yticklabels=grade_counts.index)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (Random Forest)')
plt.tight_layout()
plt.show()



############################################
# MACHINE LEARNING - PART 3: SIMPLIFIED CLASSIFICATION MODEL
############################################

# In this section, we reduce the number of grade categories to improve
# classification performance by addressing class imbalance issues

# Step 1: Redefine grade categories with broader bins
# --------------------------------------------------
# Use broader grade ranges (10 point intervals) to have fewer, more balanced classes

# Define new bins for ranges of 10
bins = [50, 60, 70, 80, 90, 101]  # Bin edges
labels = ["50-59", "60-69", "70-79", "80-89", "90-101"]  # Corresponding labels

# Apply binning
df['Grade_Category'] = pd.cut(df['Exam_Score'], bins=bins, labels=labels, include_lowest=True)

# Convert range labels to float by taking the midpoint
df['Grade_Numeric'] = df['Grade_Category'].cat.codes

# Display counts for each category
grade_counts = df['Grade_Category'].value_counts().sort_index()
print(grade_counts)

# Visualize the new grade distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='Grade_Category', data=df, order=grade_counts.index)
plt.title('Distribution of Simplified Grades')
plt.xlabel('Grade Range')
plt.ylabel('Count')
plt.tight_layout()
plt.show()


from sklearn.ensemble import RandomForestClassifier

# Step 2: Prepare data for classification with new categories
# ---------------------------------------------------------
# Similar process as before but with our new simplified grade ranges

# Convert target to categorical
y = df['Grade_Category']  # Target is the simplified grade range
X = df.drop(['Exam_Score', 'Grade_Category', 'Grade_Numeric'], axis=1)  # Features

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Train Random Forest Classifier
# -------------------------------------
# Using fewer estimators since we have simpler categories
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Step 4: Make predictions with the classifier
# -------------------------------------------
y_pred_rf = rf.predict(X_test)

# Step 5: Evaluate the simplified classifier
# -----------------------------------------
# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy: {accuracy:.4f}")

print("\nEvaluation Metrics (Random Forest):")
print(f"Accuracy: {accuracy:.4f}")

# Classification Report for detailed metrics per class
print("\nClassification Report (Random Forest):\n", classification_report(y_test, y_pred_rf))

# Generate and visualize confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_rf)

# Create a heatmap for better visualization
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=grade_counts.index,
            yticklabels=grade_counts.index)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (Random Forest)')
plt.tight_layout()
plt.show()

# Step 6: Analyze feature importance for grade prediction
# -----------------------------------------------------
# Identify which factors most strongly influence grade categories
importance = rf.feature_importances_
sorted_idx = np.argsort(importance)[::-1]
sorted_features = [X.columns[i] for i in sorted_idx]
sorted_importance = importance[sorted_idx]

# Display feature importance
plt.figure(figsize=(10, 8))
plt.barh(range(len(sorted_importance[:15])), sorted_importance[:15])
plt.yticks(range(len(sorted_importance[:15])), [sorted_features[i] for i in range(15)])
plt.xlabel('Importance')
plt.title("Top 15 Features for Grade Prediction")
plt.tight_layout()
plt.show()
